{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pohbl4/LLMtoxicLevel/blob/main/%D0%AD%D1%82%D0%B8%D0%BA%D0%B0_HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HW_2** Работу выполнил: Рон Зиннер"
      ],
      "metadata": {
        "id": "OJDdhGwl4yad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "# Get the same results each time\n",
        "np.random.seed(0)\n",
        "\n",
        "\n",
        "# Load the training data\n",
        "data = pd.read_csv(\"/content/data.csv\")\n",
        "comments = data[\"comment_text\"]\n",
        "target = (data[\"target\"]>0.7).astype(int)"
      ],
      "metadata": {
        "id": "LTCRZ6TrtiQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание №1\n"
      ],
      "metadata": {
        "id": "ym5X3-Mmc8vb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Разделение данных на обучающую и тестовую выборки\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Разделяем данные на обучающую и тестовую выборки\n",
        "# 70% данных идет на обучение, 30% - на тестирование\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    comments,           # Массив с текстовыми данными комментариев\n",
        "    target,             # Массив с метками (целевыми значениями)\n",
        "    test_size=0.3,      # Размер тестового набора (30%)\n",
        "    random_state=42     # Фиксируем начальное состояние генератора случайных чисел для воспроизводимости\n",
        ")\n",
        "\n",
        "# Объясняем, что получилось после разделения:\n",
        "print(f'Количество комментариев в обучающем наборе: {len(X_train)}')\n",
        "print(f'Количество комментариев в тестовом наборе: {len(X_test)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylpoWlkHdPW0",
        "outputId": "bf03506b-6a9b-4c82-ea38-6f1402b71919"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество комментариев в обучающем наборе: 63631\n",
            "Количество комментариев в тестовом наборе: 27271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание №2"
      ],
      "metadata": {
        "id": "qEreY_3vdXO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Создаем объект CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Преобразуем обучающие данные в матрицу признаков\n",
        "X_train_vect = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Применяем те же самые преобразования к тестовым данным\n",
        "X_test_vect = vectorizer.transform(X_test)\n",
        "\n",
        "# Выводим информацию о полученных матрицах признаков\n",
        "print(\"\\nМатрица признаков для обучающих данных:\")\n",
        "print(f\"Форма матрицы: {X_train_vect.shape}\")\n",
        "print(f\"Пример строки: {X_train_vect[0]}\")  # Показываем первую строку матрицы\n",
        "\n",
        "print(\"\\nМатрица признаков для тестовых данных:\")\n",
        "print(f\"Форма матрицы: {X_test_vect.shape}\")\n",
        "print(f\"Пример строки: {X_test_vect[0]}\")  # Показываем первую строку матрицы"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oh2Jauc4dZMF",
        "outputId": "36111039-d192-41d9-e73e-5c91c63b4dc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Матрица признаков для обучающих данных:\n",
            "Форма матрицы: (63631, 57878)\n",
            "Пример строки:   (0, 34578)\t1\n",
            "  (0, 51268)\t1\n",
            "\n",
            "Матрица признаков для тестовых данных:\n",
            "Форма матрицы: (27271, 57878)\n",
            "Пример строки:   (0, 2173)\t1\n",
            "  (0, 2598)\t1\n",
            "  (0, 3452)\t2\n",
            "  (0, 3648)\t1\n",
            "  (0, 4621)\t1\n",
            "  (0, 6015)\t1\n",
            "  (0, 6302)\t1\n",
            "  (0, 7597)\t1\n",
            "  (0, 8554)\t1\n",
            "  (0, 8912)\t1\n",
            "  (0, 9823)\t1\n",
            "  (0, 10917)\t1\n",
            "  (0, 11695)\t1\n",
            "  (0, 14836)\t1\n",
            "  (0, 15271)\t1\n",
            "  (0, 15463)\t1\n",
            "  (0, 17173)\t1\n",
            "  (0, 17471)\t1\n",
            "  (0, 18108)\t1\n",
            "  (0, 18247)\t1\n",
            "  (0, 18995)\t2\n",
            "  (0, 19246)\t1\n",
            "  (0, 20166)\t1\n",
            "  (0, 24035)\t1\n",
            "  (0, 26294)\t1\n",
            "  :\t:\n",
            "  (0, 39733)\t1\n",
            "  (0, 39822)\t1\n",
            "  (0, 40255)\t1\n",
            "  (0, 41835)\t1\n",
            "  (0, 42333)\t1\n",
            "  (0, 42399)\t1\n",
            "  (0, 47946)\t1\n",
            "  (0, 47995)\t1\n",
            "  (0, 47996)\t2\n",
            "  (0, 48126)\t1\n",
            "  (0, 49969)\t2\n",
            "  (0, 51368)\t1\n",
            "  (0, 51383)\t4\n",
            "  (0, 51651)\t1\n",
            "  (0, 52033)\t3\n",
            "  (0, 53098)\t1\n",
            "  (0, 53349)\t1\n",
            "  (0, 54613)\t1\n",
            "  (0, 55952)\t1\n",
            "  (0, 55977)\t4\n",
            "  (0, 56319)\t1\n",
            "  (0, 56461)\t1\n",
            "  (0, 56614)\t1\n",
            "  (0, 56766)\t2\n",
            "  (0, 57514)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание №3"
      ],
      "metadata": {
        "id": "CUopkTeseWCk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Создаем модель логистической регрессии с параметром max_iter=2000\n",
        "model = LogisticRegression(max_iter=2000)\n",
        "\n",
        "# Обучаем модель на обучающих данных\n",
        "model.fit(X_train_vect, y_train)\n",
        "\n",
        "# Делаем предсказания на тестовых данных\n",
        "y_pred = model.predict(X_test_vect)\n",
        "\n",
        "# Оцениваем точность модели\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Выводим результат\n",
        "print(f\"Точность модели: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYhdeBjPeSuX",
        "outputId": "ffb15b37-d32f-43b2-b957-eca8eea6a9d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Точность модели: 0.9277\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание №4"
      ],
      "metadata": {
        "id": "bNvGVH-WesbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_toxicity(comment):\n",
        "    # Преобразуем комментарий в вектор признаков\n",
        "    comment_vect = vectorizer.transform([comment])\n",
        "\n",
        "    # Получаем предсказанное значение вероятности\n",
        "    toxicity_probability = model.predict_proba(comment_vect)[0][1]\n",
        "\n",
        "    return toxicity_probability"
      ],
      "metadata": {
        "id": "kPrfN0pNetYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Тест\n",
        "new_comment = \"This is a very offensive comment!\"\n",
        "toxicity_level = predict_toxicity(new_comment)\n",
        "\n",
        "print(f\"Вероятность того, что комментарий '{new_comment}' является токсичным: {toxicity_level:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cMnBT9Geyy8",
        "outputId": "8105699d-5544-45e6-9b28-6ed61fb81b88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вероятность того, что комментарий 'This is a very offensive comment!' является токсичным: 0.1714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание №5"
      ],
      "metadata": {
        "id": "Dj3l6xBie1mp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Комментарий 1\n",
        "comment_1 = \"Apples are stupid\"\n",
        "toxicity_1 = predict_toxicity(comment_1)\n",
        "print(f\"Вероятность того, что комментарий '{comment_1}' является токсичным: {toxicity_1:.4f}\")\n",
        "\n",
        "# Комментарий 2\n",
        "comment_2 = \"I love apples\"\n",
        "toxicity_2 = predict_toxicity(comment_2)\n",
        "print(f\"Вероятность того, что комментарий '{comment_2}' является токсичным: {toxicity_2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nu1iuBgme2t5",
        "outputId": "dcfc1c7f-0726-43b0-9148-0e12fe71bae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вероятность того, что комментарий 'Apples are stupid' является токсичным: 0.9991\n",
            "Вероятность того, что комментарий 'I love apples' является токсичным: 0.0590\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание №6"
      ],
      "metadata": {
        "id": "09K753uyfIP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Получаем список всех слов и соответствующих им индексов\n",
        "vocab = vectorizer.vocabulary_\n",
        "\n",
        "# Получаем коэффициенты модели\n",
        "coefficients = model.coef_[0]\n",
        "\n",
        "# Сортируем слова по убыванию их коэффициентов\n",
        "most_toxic_words = sorted(vocab, key=lambda x: coefficients[vocab[x]], reverse=True)\n",
        "\n",
        "# Выводим топ-10 наиболее токсичных слов и их коэффициенты\n",
        "for word in most_toxic_words[:10]:\n",
        "    index = vocab[word]\n",
        "    coefficient = coefficients[index]\n",
        "    print(f\"{word}: {coefficient:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWjtkeh4fQVA",
        "outputId": "29901abb-a47a-4114-d2ac-aac9110c4a93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stupid: 9.2314\n",
            "idiot: 8.7360\n",
            "idiots: 8.4673\n",
            "stupidity: 7.5438\n",
            "idiotic: 6.8495\n",
            "crap: 6.5801\n",
            "dumb: 6.4401\n",
            "pathetic: 6.4178\n",
            "hypocrite: 6.3925\n",
            "moron: 6.3571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание №7"
      ],
      "metadata": {
        "id": "0B8SeesqfcPG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Многие простые слова используются в контексте с оскорбительными или токсичными.\n",
        "Например:\n",
        "- такие слова, как \"ты\", \"я\", \"они\", \"все\" и другие, могут встречаться в большом количестве токсичных комментариев\n",
        "- также некоторые слова могут иметь разное восприятие в зависимости от культуры\n",
        "- также модель может ошибочно ассоциировать определенные слова с токсичностью просто потому, что они часто встречаются рядом с другими явно токсичными словами."
      ],
      "metadata": {
        "id": "3nNLEZhGfeSY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание №8"
      ],
      "metadata": {
        "id": "Edd9LCKJgybu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "religious_comments = [\n",
        "\"I have a christian friend\",\n",
        "\"I have a muslim friend\",\n",
        "\"I have a white friend\",\n",
        "\"I have a black friend\"\n",
        "]"
      ],
      "metadata": {
        "id": "SsldfErAf5Go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for comment in religious_comments:\n",
        "    toxicity_level = predict_toxicity(comment)\n",
        "    print(f\"Комментарий: '{comment}'\\nТоксичность: {toxicity_level:.4f}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeAszd5QhRaw",
        "outputId": "e5f4b27b-22e1-433b-92e8-7a7bc1842f36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Комментарий: 'I have a christian friend'\n",
            "Токсичность: 0.1891\n",
            "\n",
            "Комментарий: 'I have a muslim friend'\n",
            "Токсичность: 0.5160\n",
            "\n",
            "Комментарий: 'I have a white friend'\n",
            "Токсичность: 0.4068\n",
            "\n",
            "Комментарий: 'I have a black friend'\n",
            "Токсичность: 0.5951\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание №8.1"
      ],
      "metadata": {
        "id": "xsNGy3vnhsm3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Предвзятость модели есть. Основные причины предвзятости модели:\n",
        "- Несбалансированные данные: Если в обучающем наборе данных было больше токсичных комментариев, направленных против одной религии, чем против других, модель может научиться воспринимать эту религию как более токсичную.\n",
        "- Контекст: Некоторые слова или фразы могут иметь разные коннотации в разных культурах или контекстах. Модель может неправильно интерпретировать эти различия.\n",
        "- Ну и основа, это ограниченный объем данных. Каким большим бы не был датасет, модель в любом случае не сможет учесть и обучится определять все токсичные конструкции, всех языков, \"жаргонов\", также достаточно сложно будет объяснить модели что такое \"Ирония\" :D и т.д."
      ],
      "metadata": {
        "id": "aS0VTW8kh2tT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание №9"
      ],
      "metadata": {
        "id": "JyAMrAIBjQDh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Способы уменьшения предвзятости:**\n",
        "- Разнообразие данных: просто увеличить датасет и привести разные примеры\n",
        "- Ручная проверка и коррекция: можно поработать над самим датосетом в его нынешнем виде и кодкорректировать данные для их баланса\n",
        "- Дебайсинг"
      ],
      "metadata": {
        "id": "mACHpMFnjnLs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание №10"
      ],
      "metadata": {
        "id": "BkUoqRUHklT7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Идеи для улучшения:**\n",
        "\n",
        "- Расширение и балансировка обучающего набора данных\n",
        "> Добавить дополнительные данные, содержащие разнообразные комментарии, касающиеся различных религий.\\\n",
        "> Перепроверить, что в обучающем наборе данных представлены как положительные, так и отрицательные примеры для каждой религии.\\\n",
        "> Использование методов балансировки данных, такие как оверсэмплинг или андерсэмплинг, чтобы гарантировать равное представительство каждой группы.\n",
        "- Применение методов уменьшения предвзятости\n",
        ">Использование алгоритма обучения с учетом справедливости, такие как Adversarial Debiasing или Fairness Constraints, чтобы минимизировать влияние предвзятых признаков на результаты модели.\\\n",
        ">Применение регуляризации, чтобы предотвратить переобучение модели на предвзятые данные.\n",
        "\n"
      ],
      "metadata": {
        "id": "tVNBuczxkoQF"
      }
    }
  ]
}